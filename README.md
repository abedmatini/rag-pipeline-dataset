# rag-pipeline-dataset

Build a RAG pipeline using dataset containing news information with local LLM integration.

## Project Status

**ðŸŽ‰ Complete Implementation**: RAG pipeline is fully functional with all core components working.

**âœ… Completed Components:**

- âœ… Local LLM integration with LM Studio
- âœ… Utilities for embeddings and retrieval
- âœ… Testing framework without external dependencies
- âœ… Environment setup and documentation
- âœ… **Main RAG pipeline notebook** with complete implementation
- âœ… **Core pipeline functions** - all exercises completed and tested
- âœ… **Data formatting and retrieval** - fully working

**ðŸš€ Ready to Use:**

- Complete RAG pipeline with semantic search
- Query-based news retrieval system
- Document formatting for prompts
- Unit-tested and validated functions

## Project Overview

This project implements a Retrieval-Augmented Generation (RAG) pipeline that:

- Uses local embeddings for semantic search through news articles
- Integrates with LM Studio for local LLM inference
- Provides interactive widgets for comparing RAG vs non-RAG responses
- Includes testing utilities for validation

## Project Structure

```
rag-pipeline-dataset/
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ .gitignore                  # Git ignore patterns
â”œâ”€â”€ rag_pipeline_news.ipynb     # Main Jupyter notebook
â”œâ”€â”€ utils.py                    # Core utilities and functions
â”œâ”€â”€ unittests.py                # Testing framework
â”œâ”€â”€ news_data_dedup.csv         # News dataset (when available)
â”œâ”€â”€ embeddings.joblib           # Pre-computed embeddings (when available)
â””â”€â”€ rag_env/                    # Virtual environment (ignored by git)
```

## Environment Setup

### Creating Virtual Environment

```bash
python3 -m venv rag_env
```

### Activating Virtual Environment

```bash
source rag_env/Scripts/activate
```

### Installing Dependencies

```bash
pip install sentence-transformers pandas numpy scikit-learn joblib requests ipywidgets jupyter
```

### Benefits

Using a virtual environment isolates your project dependencies from your system Python, preventing version conflicts and ensuring your project runs consistently across different machines.

## LM Studio Integration

This project is configured to work with **LM Studio** for local LLM inference.

### Model Setup

- **Model**: `hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF`
- **File**: `llama-3.2-1b-instruct-q8_0.gguf`
- **API Identifier**: `llama-3.2-1b-instruct`
- **Local Server**: `http://127.0.0.1:1234`

### Prerequisites

1. Install and run LM Studio
2. Load the Llama-3.2-1B-Instruct model
3. Start the local server on port 1234
4. Ensure the server is accessible at `http://127.0.0.1:1234`

## Key Components

### `utils.py`

Core utilities including:

- `generate_with_single_input()` - Interface to local LLM via LM Studio
- `retrieve()` - Semantic search using embeddings
- `read_dataframe()` - News data processing
- `display_widget()` - Interactive comparison interface
- `concatenate_fields()` - Text preprocessing

### `unittests.py`

Testing framework with:

- `test_format_relevant_data()` - Validates data formatting
- `test_get_relevant_data()` - Tests retrieval functionality
- Mock grading system (no external dependencies)

### `rag_pipeline_news.ipynb`

**Status**: âœ… **Complete Implementation** - Fully functional RAG pipeline

Contains:

- **Data Loading**: News dataset import and structure exploration
- **Core Functions**:
  - `query_news(indices)` - Retrieve documents by indices using list comprehension
  - `get_relevant_data(query, top_k)` - Semantic search with top-k retrieval
  - `format_relevant_data(documents)` - Format documents for RAG prompts
- **Testing & Validation**: All unit tests passing (8/8 tests)
- **Working Examples**: Functional queries like "Regulations about Autopilot" and "Greatest storms in the US"
- **Document Formatting**: Structured output with title, description, published date, and URL

## Usage

### Getting Started

1. **Activate environment**:

   ```bash
   source rag_env/Scripts/activate
   ```

2. **Start LM Studio** with the configured model

3. **Launch Jupyter**:

   ```bash
   jupyter notebook
   ```

4. **Open and run** `rag_pipeline_news.ipynb` (complete implementation)

### Using the RAG Pipeline

The notebook contains a fully functional RAG pipeline. Key functionality:

#### **Core Functions Available:**

```python
# Retrieve documents by indices
documents = query_news([3, 6, 9])

# Get relevant documents for any query
relevant_data = get_relevant_data("Greatest storms in the US", top_k=3)

# Format documents for RAG prompts
formatted_text = format_relevant_data(relevant_data)
```

#### **Example Queries:**

```python
# Search for specific topics
query = "Regulations about Autopilot"
results = get_relevant_data(query, top_k=1)

# Format output includes: title, description, published date, URL
formatted = format_relevant_data(results)
print(formatted)
```

#### **Testing Your Implementation:**

```python
# All unit tests pass
unittests.test_get_relevant_data(get_relevant_data)  # âœ… 8/8 tests passed
unittests.test_format_relevant_data(format_relevant_data)  # âœ… All tests passed
```

#### **Integration with LM Studio:**

```python
# Ready for RAG prompts with local LLM
prompt = f"Based on this news: {formatted_text}\nAnswer: {query}"
response = generate_with_single_input(prompt)
```

## Features

- âœ… **Complete RAG Pipeline** - Fully functional from query to formatted results
- âœ… **Local LLM Integration** - No external API keys required
- âœ… **Semantic Search** - Using sentence transformers for embeddings
- âœ… **Document Retrieval** - Fast query-based news article retrieval
- âœ… **Smart Formatting** - Structured output with title, description, date, URL
- âœ… **Robust Error Handling** - Graceful fallbacks for missing files
- âœ… **Testing Framework** - Built-in validation utilities (100% tests passing)
- âœ… **Clean Dependencies** - No external grading dependencies
- âœ… **Production Ready** - All core functions implemented and tested

## Troubleshooting

### Common Issues

1. **Model Path Error**:

   - The code automatically handles missing `MODEL_PATH` environment variable
   - Uses default model name if not set

2. **Missing Files**:

   - `embeddings.joblib` - Will show warning, generate embeddings first
   - `news_data_dedup.csv` - Provide your news dataset

3. **LM Studio Connection**:

   - Ensure LM Studio is running on `http://127.0.0.1:1234`
   - Check that the model is loaded and server is started

4. **Import Errors**:
   - All external dependencies have been removed or mocked
   - Install required packages in your virtual environment

## Next Steps

### Ready to Use

âœ… **Core RAG Pipeline Complete** - All essential functions implemented and tested

### Enhancement Opportunities

1. **Add Interactive Widgets**:

   ```python
   # Use the display_widget function for interactive comparisons
   display_widget(your_llm_function)
   ```

2. **Expand Document Formatting**:

   - Customize `format_relevant_data()` output format
   - Add more metadata fields
   - Implement different formatting styles for different use cases

3. **Advanced Querying**:

   - Experiment with different query types
   - Implement query preprocessing
   - Add query expansion techniques

4. **LLM Integration**:

   - Build end-to-end RAG prompts with `generate_with_single_input()`
   - Compare RAG vs non-RAG responses
   - Implement prompt templates

5. **Performance Optimization**:
   - Cache embeddings for faster retrieval
   - Implement batch processing
   - Add relevance scoring improvements

### Customization Examples

```python
# Customize formatting
def custom_format_relevant_data(documents):
    return "\n".join([f"ðŸ“° {doc['title']}\nðŸ’¬ {doc['description']}" for doc in documents])

# Build RAG prompts
def create_rag_prompt(query, documents):
    context = format_relevant_data(documents)
    return f"Context:\n{context}\n\nQuestion: {query}\nAnswer:"

# End-to-end RAG
def rag_query(question, top_k=3):
    docs = get_relevant_data(question, top_k)
    prompt = create_rag_prompt(question, docs)
    return generate_with_single_input(prompt)
```

### All Components Ready

- âœ… `rag_pipeline_news.ipynb` - Complete RAG implementation
- âœ… `utils.py` - LM Studio integration and utilities
- âœ… `unittests.py` - Testing framework (100% passing)
- âœ… Environment setup and documentation
